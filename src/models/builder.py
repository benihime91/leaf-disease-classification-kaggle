# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/04d_models.builder.ipynb (unless otherwise specified).

__all__ = ["build_head", "Net"]

# Cell
import timm
import torch
from omegaconf import DictConfig, OmegaConf
from torch import nn

from src import _logger as logger
from ..core import *
from .classifiers import *
from .layers import *
from .utils import apply_init, cut_model, num_features_model

# Cell
def build_head(cfg: DictConfig, nf, verbose=False):
    "builds a classifier for model with output `nf`"
    head = CLASSIFIER_REGISTERY.get(cfg.name)(nf=nf, **cfg.params)
    return head


# Cell
class Net(nn.Module):
    "Creates a model using the Global Config"

    def __init__(self, cfg: DictConfig, verbose=True):
        super(Net, self).__init__()
        self.base_conf = cfg.model.base_model
        self.head_conf = cfg.model.head

        # build the encoder
        if verbose:
            logger.info(f"Model Configuration :\n {OmegaConf.to_yaml(cfg.model, resolve=True)}")

        # configure activation of the model
        # none default layer or ReLU/SiLU for the model
        if self.base_conf.activation is not None:
            self.act = ACTIVATIONS[self.base_conf.activation]
        else:
            self.act = None

        # build encoder
        self.encoder = timm.create_model(self.base_conf.name, act_layer=self.act, **self.base_conf.params)
        self.encoder = cut_model(self.encoder, -2)
        # build the head of the model
        nf = num_features_model(self.encoder)
        self.head = build_head(self.head_conf, nf, verbose)

    def act_func(self):
        if self.act is not None:
            return self.act(inplace=True)
        else:
            if "efficientnet" in str(self.base_conf.name):
                return nn.SiLU(inplace=True)
            else:
                return nn.ReLU(inplace=True)

    def init_classifier(self):
        if self.clf_conf.act_layer == "default":
            apply_init(self.classifier, torch.nn.init.kaiming_normal_)
        else:
            apply_init(self.classifier, torch.nn.init.kaiming_uniform_)

    def get_head(self):
        return self.head

    def get_classifier(self):
        try:
            return self.head[-1]
        except:
            return self.head.fc2

    def forward_features(self, x: torch.Tensor):
        return self.encoder(x)

    def forward(self, x: torch.Tensor):
        return self.head(self.forward_features(x))

    def get_param_list(self):
        "splits the parameters of the Model"
        return [params(self.encoder[:3]), params(self.encoder[3:]), params(self.head)]
