# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_core.ipynb (unless otherwise specified).

__all__ = ['CASSAVA_MEAN', 'CASSAVA_STD', 'idx2lbl', 'conf_mat_idx2lbl', 'seed_everything', 'generate_random_id',
           'load_dataset', 'ImageClassificationFromDf', 'ifnone', 'get_train_transformations',
           'get_valid_transformations', 'FancyImageDataset', 'params', 'trainable_params']

# Cell
from typing import Any
import pandas as pd
import uuid
import math
import numpy as np
import random
import os

import cv2
from PIL import Image

import albumentations as A

import torch
import torchvision
from torchvision import transforms
from torchvision.datasets.folder import pil_loader
from timm.data.transforms import _pil_interp, RandomResizedCropAndInterpolation
from timm.data.random_erasing import RandomErasing
from timm.data.constants import (
    IMAGENET_DEFAULT_MEAN,
    IMAGENET_DEFAULT_STD,
    DEFAULT_CROP_PCT,
)

from omegaconf import DictConfig, OmegaConf


# export
CASSAVA_MEAN = (0.42984136, 0.49624753, 0.3129598)
CASSAVA_STD = (0.21417203, 0.21910103, 0.19542212)

# Cell
idx2lbl = {
    0: "Cassava Bacterial Blight (CBB)",
    1: "Cassava Brown Streak Disease (CBSD)",
    2: "Cassava Green Mottle (CGM)",
    3: "Cassava Mosaic Disease (CMD)",
    4: "Healthy",
}


conf_mat_idx2lbl = {
    0: "CBB",
    1: "CBSD",
    2: "CGM",
    3: "CMD",
    4: "Healthy",
}

# Cell
def seed_everything(seed: int) -> int:
    """sets a seed for the environment in :
       `pytorch`, `numpy`, `python.random` and sets `PYTHONHASHSEED` environment variable.
    """
    np.random.seed(seed)
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)

    # pytorch-seeds
    torch.manual_seed(seed)

    # cuda seeds
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    return seed


# export
def generate_random_id() -> str:
    "generates a random id"
    idx = uuid.uuid1()
    idx = str(idx).split("-")[0]
    return idx

# Cell
def load_dataset(
    pth: str, im_dir: str, curr_fold: int = 0, shuffle: bool = True
) -> pd.DataFrame:
    "loads the dataframe and formats it"
    assert curr_fold < 5

    data = pd.read_csv(pth)

    data["filePath"] = [
        os.path.join(im_dir, data["image_id"][idx]) for idx in range(len(data))
    ]
    data["is_valid"] = [data.kfold[n] == curr_fold for n in range(len(data))]
    data["label"].replace(idx2lbl, inplace=True)

    if shuffle:
        data = data.sample(frac=1).reset_index(drop=True, inplace=False)
    else:
        data = data.reset_index(drop=True, inplace=False)

    return data

# Cell
class ImageClassificationFromDf(torch.utils.data.Dataset):
    """
    Image classification dataset.
    Args:
        dataframe: dataframe with image_id and labels
        transformations: albumentation transformations
    """

    def __init__(
        self,
        dataframe: pd.DataFrame,
        transformations: A.Compose,
        lbl_dict: dict = None,
        *args,
        **kwargs
    ):
        self.df = dataframe
        self.transforms = transformations

        if lbl_dict is None:
            self.lbl_dict = {v: k for k, v in idx2lbl.items()}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        image_id = self.df["filePath"][idx]
        target = self.df["label"][idx]

        # Read an image with OpenCV
        img = cv2.imread(image_id)

        # By default OpenCV uses BGR color space for color images,
        # so we need to convert the image to RGB color space.
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # apply transformations to the image
        img = self.transforms(image=img)["image"]

        return img, torch.tensor(self.lbl_dict[target])

# Cell
def ifnone(a: Any, b: Any) -> Any:
    "`a` if `a` is not None, otherwise `b`."
    return b if a is None else a

# Cell
## some advanced data-augmentation functions & classes
## These are adapted from : https://github.com/rwightman/pytorch-image-models/tree/master/timm
## Image augmentations are done via torchvision transformations and some custom functions from timm

# Cell
def get_train_transformations(cfg: DictConfig):
    scale = tuple(cfg.scale or (0.08, 1.0))  # default imagenet scale range
    ratio = tuple(cfg.ratio or (3.0 / 4.0, 4.0 / 3.0))  # default imagenet ratio range

    primary_tfml = [
        RandomResizedCropAndInterpolation(
            cfg.img_size, scale=scale, ratio=ratio, interpolation=cfg.interpolation
        )
    ]

    if cfg.hflip > 0.0:
        primary_tfml += [transforms.RandomHorizontalFlip(cfg.hflip)]
    if cfg.vflip > 0.0:
        primary_tfml += [transforms.RandomVerticalFlip(cfg.vflip)]

    secondary_tfml = []

    if cfg.color_jitter is not None:
        color_jitter = (float(cfg.color_jitter),) * 3
        secondary_tfml += [transforms.ColorJitter(*color_jitter)]

    final_tfml = []

    if cfg.mean == "cassava" and cfg.std == "cassava":
        mean, std = CASSAVA_MEAN, CASSAVA_STD
    else:
        mean = ifnone(cfg.mean, IMAGENET_DEFAULT_MEAN)
        std = ifnone(cfg.std, IMAGENET_DEFAULT_STD)

    mean, std = torch.tensor(mean), torch.tensor(std)

    final_tfml += [transforms.ToTensor(), transforms.Normalize(mean, std)]

    if cfg.re_prob > 0.0:
        final_tfml.append(
            RandomErasing(
                cfg.re_prob,
                mode=cfg.re_mode,
                max_count=cfg.re_count,
                num_splits=cfg.re_num_splits,
                device="cpu",
            )
        )

    return transforms.Compose(primary_tfml + secondary_tfml + final_tfml)

# Cell
def get_valid_transformations(cfg: DictConfig):
    cfg.crop_pct = ifnone(cfg.crop_pct, DEFAULT_CROP_PCT)

    if cfg.mean == "cassava" and cfg.std == "cassava":
        mean, std = CASSAVA_MEAN, CASSAVA_STD
    else:
        mean = ifnone(cfg.mean, IMAGENET_DEFAULT_MEAN)
        std = ifnone(cfg.std, IMAGENET_DEFAULT_STD)

    scale_size = int(math.floor(cfg.img_size / cfg.crop_pct))

    tfl = [
        transforms.Resize(scale_size, _pil_interp(cfg.interpolation)),
        transforms.CenterCrop(cfg.img_size),
    ]

    tfl += [
        transforms.ToTensor(),
        transforms.Normalize(mean=torch.tensor(mean), std=torch.tensor(std)),
    ]
    return transforms.Compose(tfl)

# Cell
class FancyImageDataset(torch.utils.data.Dataset):
    """
    Image classification dataset.

    Args:
        dataframe: dataframe with image_id and labels
        cfg: a hudra configuration file
        transforms: a torchvision.transforms.Compose instance
        lbl: a label-integer mapping
    """

    def __init__(
        self,
        dataframe: pd.DataFrame,
        cfg: DictConfig,
        transforms: transforms.Compose = None,
        lbl_dict: dict = None,
        *args,
        **kwargs
    ):
        self.df = dataframe

        if lbl_dict is None:
            self.lbl_dict = {v: k for k, v in idx2lbl.items()}

        self.num_iters: int = cfg.mixmethod.steps
        self.batch_size: int = cfg.datamodule.bs
        self.total_samples: int = self.num_iters * self.batch_size
        self.curr_step: int = 0

        if transforms is None:
            initial_cfg = cfg.augmentations.train.params.re_prob

            cfg.augmentations.train.params.re_prob = 0.0
            self.initial_tfms = get_train_transformations(
                cfg.augmentations.train.params
            )

            cfg.augmentations.train.params.re_prob = initial_cfg
            self.tfms = get_train_transformations(cfg.augmentations.train.params)
        else:
            self.initial_tfms = None
            self.tfms = transforms

        self.curr_tfms: transforms.Compose = None

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        image_id = self.df["filePath"][idx]
        target = self.df["label"][idx]

        # apply transformations to the image
        sample = pil_loader(image_id)

        if self.curr_step < self.total_samples:
            tfm = ifnone(self.initial_tfms, self.tfms)
            self.curr_tfms = tfm

        else:
            self.curr_tfms = self.tfms

        sample = self.curr_tfms(sample)
        self.curr_step += 1

        return sample, torch.tensor(self.lbl_dict[target])

# Cell
def params(m):
    "Return all parameters of `m`"
    return [p for p in m.parameters()]

# Cell
def trainable_params(m):
    "Return all trainable parameters of `m`"
    return [p for p in m.parameters() if p.requires_grad]