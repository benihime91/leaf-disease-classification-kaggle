# AUTOGENERATED BY NBDEV! DO NOT EDIT!

__all__ = ["index", "modules", "custom_doc_links", "git_url"]

index = {"idx2lbl": "00_core.ipynb",
         "conf_mat_idx2lbl": "00_core.ipynb",
         "seed_everything": "00_core.ipynb",
         "generate_random_id": "00_core.ipynb",
         "params": "00_core.ipynb",
         "trainable_params": "00_core.ipynb",
         "load_data": "01a_data.datasets.ipynb",
         "pil_loader": "01a_data.datasets.ipynb",
         "cv2_loader": "01a_data.datasets.ipynb",
         "CassavaDataset": "01a_data.datasets.ipynb",
         "create_transform": "01b_data.datasests_factory.ipynb",
         "DatasetMapper": "01b_data.datasests_factory.ipynb",
         "BaseMixMethodHandler": "01c_data.mixmethods.ipynb",
         "Mixup": "01c_data.mixmethods.ipynb",
         "Cutmix": "01c_data.mixmethods.ipynb",
         "Snapmix": "01c_data.mixmethods.ipynb",
         "LabelSmoothingCrossEntropy": "02_losses.ipynb",
         "log_t": "02_losses.ipynb",
         "exp_t": "02_losses.ipynb",
         "compute_normalization_fixed_point": "02_losses.ipynb",
         "compute_normalization": "02_losses.ipynb",
         "tempered_softmax": "02_losses.ipynb",
         "bi_tempered_logistic_loss": "02_losses.ipynb",
         "BiTemperedLogisticLoss": "02_losses.ipynb",
         "TaylorSoftmax": "02_losses.ipynb",
         "TaylorCrossEntropyLoss": "02_losses.ipynb",
         "OPTIM_REGISTERY": "03a_optimizers.ipynb",
         "Ranger": "03a_optimizers.ipynb",
         "create_optimizer": "03a_optimizers.ipynb",
         "SCHEDULER_REGISTERY": "03b_schedulers.ipynb",
         "FlatCosScheduler": "03b_schedulers.ipynb",
         "ConstantWarmup": "03b_schedulers.ipynb",
         "LinearWarmup": "03b_schedulers.ipynb",
         "CosineWarmup": "03b_schedulers.ipynb",
         "PolynomialDecayWarmup": "03b_schedulers.ipynb",
         "step_schedulers": "03b_schedulers.ipynb",
         "warmup_schedulers": "03b_schedulers.ipynb",
         "training_steps": "03b_schedulers.ipynb",
         "create_scheduler": "03b_schedulers.ipynb",
         "norm_types": "04a_models.utils.ipynb",
         "requires_grad": "04a_models.utils.ipynb",
         "init_default": "04a_models.utils.ipynb",
         "cond_init": "04a_models.utils.ipynb",
         "apply_leaf": "04a_models.utils.ipynb",
         "apply_init": "04a_models.utils.ipynb",
         "cut_model": "04a_models.utils.ipynb",
         "num_features_model": "04a_models.utils.ipynb",
         "MishJitAutoFn": "04b_models.layers.ipynb",
         "mish": "04b_models.layers.ipynb",
         "Mish": "04b_models.layers.ipynb",
         "ACTIVATIONS": "04b_models.layers.ipynb",
         "AdaptiveConcatPool2d": "04b_models.layers.ipynb",
         "NormType": "04b_models.layers.ipynb",
         "BatchNorm": "04b_models.layers.ipynb",
         "LinBnDrop": "04b_models.layers.ipynb",
         "gem": "04b_models.layers.ipynb",
         "GeM": "04b_models.layers.ipynb",
         "RMSNorm": "04b_models.layers.ipynb",
         "CLASSIFIER_REGISTERY": "04c_models.classifiers.ipynb",
         "CnnHeadV0": "04c_models.classifiers.ipynb",
         "CnnHeadV1": "04c_models.classifiers.ipynb",
         "CnnHeadV2": "04c_models.classifiers.ipynb",
         "build_head": "04d_models.builder.ipynb",
         "Net": "04d_models.builder.ipynb",
         "Task": "04e_models.task.ipynb",
         "WandbTask": "05_callbacks.ipynb",
         "DisableValidationBar": "05_callbacks.ipynb",
         "LogInformationCallback": "05_callbacks.ipynb"}

modules = ["core.py",
           "data/datasets.py",
           "data/dataset_factory.py",
           "data/mixmethods.py",
           "losses.py",
           "optimizers.py",
           "schedulers.py",
           "models/utils.py",
           "models/layers.py",
           "models/classifiers.py",
           "models/builder.py",
           "models/task.py",
           "callbacks.py"]

doc_url = "https://fastai.github.io/src/"

git_url = "https://github.com/fastai/src/tree/master/"

def custom_doc_links(name): return None
