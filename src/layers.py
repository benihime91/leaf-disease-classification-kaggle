# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02_layers.ipynb (unless otherwise specified).

__all__ = ['AdaptiveConcatPool2d', 'Mish', 'cut_model', 'num_features_model', 'create_head', 'replace_activs']

# Cell
import torch
from torch import nn
import torch.nn.functional as F

# Cell
class AdaptiveConcatPool2d(nn.Module):
    "Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d` from FastAI"

    def __init__(self, size=None):
        super(AdaptiveConcatPool2d, self).__init__()
        self.size = size or 1
        self.ap = nn.AdaptiveAvgPool2d(self.size)
        self.mp = nn.AdaptiveMaxPool2d(self.size)

    def forward(self, x):
        return torch.cat([self.mp(x), self.ap(x)], 1)

# Cell
class Mish(nn.Module):
    "Mish activation"
    def __init__(self):
        super().__init__()

    def forward(self, x):
        return x * (torch.tanh(F.softplus(x)))

# Cell
def cut_model(model: nn.Module, n: int = -2):
    "cuts `model` layers upto `n`"
    ls = list(model.children())[:n]
    encoder = nn.Sequential(*ls)
    return encoder


def num_features_model(m: nn.Module, in_chs:int = 3):
    "Return the number of output features for `m`."
    m.to('cpu')
    dummy_inp = torch.zeros((32, in_chs, 120, 120))
    dummy_out = m(dummy_inp)
    return dummy_out.size()[1]

# Cell
def create_head(nf: int, n_out: int, lin_ftrs: int = 512, act: nn.Module = nn.ReLU(inplace=True)):
    "create a custom head for a classifier from FastAI"
    lin_ftrs = [nf, lin_ftrs, n_out]

    pool = AdaptiveConcatPool2d()

    layers = [pool, nn.Flatten()]

    layers += [
        nn.BatchNorm1d(lin_ftrs[0]),
        nn.Dropout(0.25),
        act,
        nn.Linear(lin_ftrs[0], lin_ftrs[1], bias=False),
        nn.BatchNorm1d(lin_ftrs[1]),
        nn.Dropout(0.5),
        act,
        nn.Linear(lin_ftrs[1], lin_ftrs[2], bias=False),
    ]
    return nn.Sequential(*layers)

# Cell
def replace_activs(model, func, activs: list = [nn.ReLU, nn.SiLU]):
    "recursively replace all the `activs` with `func`"
    for child_name, child in model.named_children():
        for act in activs:
            if isinstance(child, act):
                setattr(model, child_name, func)
        else:
            replace_activs(child, func)