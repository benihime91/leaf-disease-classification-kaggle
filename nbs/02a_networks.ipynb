{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.core import *\n",
    "from src.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TransferLearningModel(nn.Module):\n",
    "    \"Transfer Learning with `encoder`\"\n",
    "    def __init__(self, encoder:nn.Module, c:int, cut:int=-2, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder: the classifer to extract features\n",
    "            c: number of output classes\n",
    "            cut: number of layers to cut/keep from the encoder\n",
    "            **kwargs: arguments for `create_head`\n",
    "        \"\"\"\n",
    "        super(TransferLearningModel, self).__init__()\n",
    "        \n",
    "        self.encoder_name = encoder.__class__.__name__\n",
    "        # cut layers from the encoder\n",
    "        self.encoder = cut_model(encoder, cut)\n",
    "        # create the custom head for the model\n",
    "        feats  = num_features_model(self.encoder, in_chs=3) * 2\n",
    "        self.c = c\n",
    "        self.fc = create_head(feats, n_out=c, **kwargs)\n",
    "           \n",
    "    @property\n",
    "    def encoder_class_name(self): \n",
    "        return self.encoder_name\n",
    "        \n",
    "    def forward(self, xb): \n",
    "        return self.fc(self.encoder(xb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransferLearningModel(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): AdaptiveConcatPool2d(\n",
      "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
      "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
      "    )\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): Linear(in_features=512, out_features=5, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = TransferLearningModel(timm.create_model('resnet18'), c=5, cut=-2)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inp = torch.zeros((32, 3, 120, 120))\n",
    "dummy_out = m(dummy_inp)\n",
    "dummy_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#TODO: add midlevel classification branch in learning.\n",
    "class SnapMixTransferLearningModel(nn.Module):\n",
    "    \"Transfer Learning with model to be comaptible with Snapmix\"\n",
    "    def __init__(self, encoder:nn.Module, c:int, cut:int=-2, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder: the classifer to extract features\n",
    "            c: number of output classes\n",
    "            cut: number of layers to cut/keep from the encoder\n",
    "        \"\"\"\n",
    "        super(SnapMixTransferLearningModel, self).__init__()\n",
    "        \n",
    "        try   : feats  = encoder.fc.in_features\n",
    "        except: feats  = encoder.classifier.in_features\n",
    "        \n",
    "        self.encoder_name = encoder.__class__.__name__\n",
    "        # cut layers from the encoder\n",
    "        self.encoder = cut_model(encoder, cut)\n",
    "        # create the custom head for the model\n",
    "        \n",
    "        self.c     = c\n",
    "        self.pool  = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        layers  = [nn.Flatten(), nn.BatchNorm1d(feats), nn.Dropout(0.5)]\n",
    "        self.ls = nn.Sequential(*layers)\n",
    "        \n",
    "        self.fc = nn.Linear(feats, self.c)\n",
    "        \n",
    "    def mid_forward(self, xb, detach=True): \n",
    "        pass  \n",
    "              \n",
    "    @property\n",
    "    def encoder_class_name(self): \n",
    "        return self.encoder_name\n",
    "        \n",
    "    def forward(self, xb): \n",
    "        fmps = self.encoder(xb)\n",
    "        x = self.pool(fmps)\n",
    "        x = self.ls(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SnapMixTransferLearningModel(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU(inplace=True)\n",
      "    (3): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): DepthwiseSeparableConv(\n",
      "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "          (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (5): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): SiLU(inplace=True)\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (ls): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=1280, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = SnapMixTransferLearningModel(timm.create_model('efficientnet_b0'), c=5, cut=-2)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inp = torch.zeros((32, 3, 120, 120))\n",
    "dummy_out = m(dummy_inp)\n",
    "dummy_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lightning.core import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0150, -0.0100, -0.0052,  ..., -0.0071,  0.0052, -0.0142],\n",
       "         [-0.0220, -0.0195, -0.0164,  ..., -0.0273, -0.0100,  0.0051],\n",
       "         [-0.0248, -0.0279,  0.0106,  ..., -0.0233, -0.0221,  0.0018],\n",
       "         [ 0.0131,  0.0140,  0.0067,  ..., -0.0050, -0.0079,  0.0048],\n",
       "         [-0.0221, -0.0176,  0.0182,  ..., -0.0011,  0.0056, -0.0138]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0102,  0.0055,  0.0102, -0.0047,  0.0215], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list = params(m.fc) + params(m.ls)\n",
    "param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(params=param_list, lr=1e03)\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00a_lightning.core.ipynb.\n",
      "Converted 00b_fastai.core.ipynb.\n",
      "Converted 01_mixmethods.ipynb.\n",
      "Converted 02_layers.ipynb.\n",
      "Converted 02a_networks.ipynb.\n",
      "Converted 03_optimizers.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
