{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'leaf-disease-classification-kaggle'...\r\n",
      "remote: Enumerating objects: 17, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Total 1269 (delta 0), reused 7 (delta 0), pack-reused 1252\u001b[K\r\n",
      "Receiving objects: 100% (1269/1269), 41.94 MiB | 22.22 MiB/s, done.\r\n",
      "Resolving deltas: 100% (714/714), done.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/benihime91/leaf-disease-classification-kaggle.git\n",
    "!wandb login a74f67fd5fae293e301ea8b6710ee0241f595a63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timmmodels/pytorch-image-models/')\n",
    "sys.path.append('leaf-disease-classification-kaggle/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from fastai.torch_core import apply_init\n",
    "from functools import partial\n",
    "import wandb\n",
    "\n",
    "from src.core import *\n",
    "from src.lightning.core import *\n",
    "from src.layers import *\n",
    "from src.mixmethods import *\n",
    "from src.networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = seed_everything(42)\n",
    "idx  = generate_random_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure the training paramters/job\n",
    "config = {\n",
    " \"random_seed\": seed,\n",
    " \"unique_idx\" : idx,\n",
    "    \n",
    " # name of the Wandb project name\n",
    " \"project_name\" : \"kaggle-leaf-disease-v2\",\n",
    "    \n",
    " # current fold of data to take as validation, other folds are used as\n",
    " # train data\n",
    " \"curr_fold\" : 0 ,\n",
    " # path to where the images are present\n",
    " \"image_dir\" : \"../input/cassava-leaf-disease-classification/train_images/\",\n",
    " # path to the stratified 5 folds csv data for cassava\n",
    " \"csv_path\"  : \"leaf-disease-classification-kaggle/data/stratified-data-5folds.csv\",\n",
    "    \n",
    " # settings for the model architecture\n",
    " \"encoder\"   : \"resnext50_32x4d\",\n",
    " \"activation\": nn.ReLU(inplace=True),\n",
    " \"image_dims\": 512,\n",
    "    \n",
    " # settings for the training job\n",
    " \"num_epochs\": 30,\n",
    "    \n",
    " # Adam parameters from https://docs.fast.ai/optimizer.html#Adam\n",
    " \"opt_func\"  : partial(optim.AdamW, weight_decay=1e-02, eps=1e-05, betas=(0.9, 0.99)),\n",
    " \"scheduler\" : partial(optim.lr_scheduler.CosineAnnealingWarmRestarts, T_0=10, T_mult=1),\n",
    "    \n",
    " # when to call scheduler.step() -- \"step\" or \"epoch\"\n",
    " \"scheduler_step\" : \"step\",\n",
    " \"metric_to_track\": None,\n",
    "    \n",
    " \"mixmethod\" : partial(SnapMix, alpha=5.0, conf_prob=1.0, mid_level=False),\n",
    " \"loss_func\" : LabelSmoothingCrossEntropy(),\n",
    "    \n",
    " \"batch_size\": 32,\n",
    " \n",
    " # initial learning rate for the optimizer\n",
    " \"init_lr\": 1e-03,\n",
    " \"lr_mult\": 100,\n",
    "}\n",
    "\n",
    "# Albumentations augmentations for train/ valid data\n",
    "TRAIN_AUGS = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomResizedCrop(config[\"image_dims\"], config[\"image_dims\"]), \n",
    "        A.CenterCrop(config[\"image_dims\"], config[\"image_dims\"])], \n",
    "    p=0.7),\n",
    "    A.Resize(config[\"image_dims\"], config[\"image_dims\"], p=1.0),\n",
    "    A.OneOf([A.ShiftScaleRotate(), A.HorizontalFlip()], p=0.8),\n",
    "    A.OneOf([A.RandomBrightnessContrast(), A.HueSaturationValue()], p=0.5),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0)\n",
    "])\n",
    "    \n",
    "VALID_AUGS = A.Compose([\n",
    "    A.CenterCrop(config[\"image_dims\"], config[\"image_dims\"], p=1.0),\n",
    "    A.Resize(config[\"image_dims\"], config[\"image_dims\"], p=1.0), \n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "\n",
    "MODEL_SAVE_PATH = f\"{config['encoder']}-fold={config['curr_fold']}-{idx}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnext50_32x4d_ra-d733960d.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d_ra-d733960d.pth\n"
     ]
    }
   ],
   "source": [
    "# initate the model architecture\n",
    "# for snapmix we will call BasicTransferLearningModel class to init a model\n",
    "# suitable for snapmix, we can also use TransferLearningModel class to init\n",
    "# a model similar to the model created by the fast.ai cnn_learner func\n",
    "\n",
    "encoder = timm.create_model(config[\"encoder\"], pretrained=True)\n",
    "model = SnapMixTransferLearningModel(encoder=encoder, c=len(idx2lbl), \n",
    "                                    cut=-2, act=config[\"activation\"])\n",
    "\n",
    "# init the weights of the final untrained layer\n",
    "apply_init(model.fc, torch.nn.init.kaiming_normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SnapMixTransferLearningModel(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mixmethod : functools.partial(<class 'src.mixmethods.SnapMix'>, alpha=5.0, conf_prob=1.0, mid_level=False)\n",
      "Loss Function : LabelSmoothingCrossEntropy()\n"
     ]
    }
   ],
   "source": [
    "# init the LightingDataModule + LightningModule\n",
    "dm = CassavaLightningDataModule(config[\"csv_path\"], config[\"image_dir\"], \n",
    "                                curr_fold=config[\"curr_fold\"], \n",
    "                                train_augs=TRAIN_AUGS, \n",
    "                                valid_augs=VALID_AUGS, \n",
    "                                bs=config[\"batch_size\"], \n",
    "                                num_workers=4)\n",
    "\n",
    "litModel = LightningCassava(model,opt_func=config[\"opt_func\"],\n",
    "                        lr=config[\"init_lr\"], lr_mult=config[\"lr_mult\"],\n",
    "                        step_after=config[\"scheduler_step\"],\n",
    "                        scheduler=config[\"scheduler\"],\n",
    "                        loss_func=config[\"loss_func\"],\n",
    "                        mixmethod=config[\"mixmethod\"], \n",
    "                        metric_to_track=config[\"metric_to_track\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "# initialize pytorch_lightning Trainer + Callbacks\n",
    "callbacks = [\n",
    "    pl.callbacks.LearningRateMonitor(\"step\"), \n",
    "    WandbImageClassificationCallback(dm),\n",
    "]\n",
    "\n",
    "chkpt_callback = pl.callbacks.ModelCheckpoint(monitor=\"valid/acc\",\n",
    "                                              save_top_k=1,\n",
    "                                              mode='max')\n",
    "\n",
    "wb_logger = pl.loggers.WandbLogger(project=config[\"project_name\"])\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, precision=16, log_every_n_steps=1,\n",
    "                    gradient_clip_val=0, accumulate_grad_batches=3,\n",
    "                    max_epochs=config[\"num_epochs\"], callbacks=callbacks,\n",
    "                    checkpoint_callback=chkpt_callback, logger=wb_logger,\n",
    "                    deterministic=True, default_root_dir=\"/kaggle/working/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data for fold: 0\n",
      "Using functools.partial(<class 'torch.optim.adamw.AdamW'>, weight_decay=0.01, eps=1e-05, betas=(0.9, 0.99))\n",
      "Using functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'>, T_0=10, T_mult=1)\n",
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | SnapMixTransferLearningModel | 23.0 M\n",
      "leaf-disease-classification-kaggle/src/mixmethods.py:143: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  clslogit = F.softmax(clsw.forward(poolfea))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7438399054b14711b93aed148f4c2f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start learning_rate finder to find optimum starting Lr\n",
    "lr_finder = trainer.tuner.lr_find(litModel, datamodule=dm)\n",
    "\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using functools.partial(<class 'torch.optim.adamw.AdamW'>, weight_decay=0.01, eps=1e-05, betas=(0.9, 0.99))\n",
      "Using functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'>, T_0=10, T_mult=1)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mayushman\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">young-shadow-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ayushman/kaggle-leaf-disease-v2\" target=\"_blank\">https://wandb.ai/ayushman/kaggle-leaf-disease-v2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ayushman/kaggle-leaf-disease-v2/runs/179br06w\" target=\"_blank\">https://wandb.ai/ayushman/kaggle-leaf-disease-v2/runs/179br06w</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20201226_213308-179br06w</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | SnapMixTransferLearningModel | 23.0 M\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4025e1967f430680bfd129dd142a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670ad13c20eb49b690baae2efad2cab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "leaf-disease-classification-kaggle/src/mixmethods.py:143: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  clslogit = F.softmax(clsw.forward(poolfea))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e1ed46f9ea48a6bc0fa99eeb248418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 180 < 181; dropping {'lr-AdamW/pg1': 2.447174185242324e-07, 'lr-AdamW/pg2': 2.4471741852423235e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 180 < 181; dropping {'train/loss_step': 1.5626304149627686, 'train/acc_step': 0.78125, 'epoch': 2}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 180 < 181; dropping {'lr-AdamW/pg1': 2.447174185242324e-07, 'lr-AdamW/pg2': 2.4471741852423235e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 180 < 181; dropping {'train/loss_step': 1.8353142738342285, 'train/acc_step': 0.65625, 'epoch': 2}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 180 < 181; dropping {'lr-AdamW/pg1': 2.447174185242324e-07, 'lr-AdamW/pg2': 2.4471741852423235e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 180 < 181; dropping {'train/loss_step': 1.4762122631072998, 'train/acc_step': 0.6875, 'epoch': 2}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b72f1375bd4a97a872f4a501fbb7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 359 < 360; dropping {'lr-AdamW/pg1': 9.549150281252633e-07, 'lr-AdamW/pg2': 9.549150281252633e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 359 < 360; dropping {'train/loss_step': 1.6031370162963867, 'train/acc_step': 0.53125, 'epoch': 3}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 359 < 360; dropping {'lr-AdamW/pg1': 9.549150281252633e-07, 'lr-AdamW/pg2': 9.549150281252633e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 359 < 360; dropping {'train/loss_step': 1.7638871669769287, 'train/acc_step': 0.59375, 'epoch': 3}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 359 < 360; dropping {'lr-AdamW/pg1': 9.549150281252633e-07, 'lr-AdamW/pg2': 9.549150281252633e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 359 < 360; dropping {'train/loss_step': 1.6682155132293701, 'train/acc_step': 0.65625, 'epoch': 3}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026804cb38674e4eaf0ed985ecdfdc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 538 < 539; dropping {'lr-AdamW/pg1': 2.061073738537635e-06, 'lr-AdamW/pg2': 0.00020610737385376348}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 538 < 539; dropping {'train/loss_step': 1.5889679193496704, 'train/acc_step': 0.78125, 'epoch': 4}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 538 < 539; dropping {'lr-AdamW/pg1': 2.061073738537635e-06, 'lr-AdamW/pg2': 0.00020610737385376348}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 538 < 539; dropping {'train/loss_step': 1.864989995956421, 'train/acc_step': 0.46875, 'epoch': 4}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 538 < 539; dropping {'lr-AdamW/pg1': 2.061073738537635e-06, 'lr-AdamW/pg2': 0.00020610737385376348}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 538 < 539; dropping {'train/loss_step': 1.530360221862793, 'train/acc_step': 0.8125, 'epoch': 4}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8ac7417b234ace8617f611bc99c83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 717 < 718; dropping {'lr-AdamW/pg1': 3.4549150281252635e-06, 'lr-AdamW/pg2': 0.00034549150281252633}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 717 < 718; dropping {'train/loss_step': 1.6057534217834473, 'train/acc_step': 0.78125, 'epoch': 5}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 717 < 718; dropping {'lr-AdamW/pg1': 3.4549150281252635e-06, 'lr-AdamW/pg2': 0.00034549150281252633}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 717 < 718; dropping {'train/loss_step': 1.4858930110931396, 'train/acc_step': 0.6875, 'epoch': 5}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 717 < 718; dropping {'lr-AdamW/pg1': 3.4549150281252635e-06, 'lr-AdamW/pg2': 0.00034549150281252633}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 717 < 718; dropping {'train/loss_step': 1.3329057693481445, 'train/acc_step': 0.59375, 'epoch': 5}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12258ec2aea4ae8a2d61ae9e7be82ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 896 < 897; dropping {'lr-AdamW/pg1': 5e-06, 'lr-AdamW/pg2': 0.0005}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 896 < 897; dropping {'train/loss_step': 1.7223092317581177, 'train/acc_step': 0.53125, 'epoch': 6}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 896 < 897; dropping {'lr-AdamW/pg1': 5e-06, 'lr-AdamW/pg2': 0.0005}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 896 < 897; dropping {'train/loss_step': 1.569311499595642, 'train/acc_step': 0.59375, 'epoch': 6}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 896 < 897; dropping {'lr-AdamW/pg1': 5e-06, 'lr-AdamW/pg2': 0.0005}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 896 < 897; dropping {'train/loss_step': 1.5710110664367676, 'train/acc_step': 0.53125, 'epoch': 6}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34db170ecb044019bb167b89719df1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1075 < 1076; dropping {'lr-AdamW/pg1': 6.545084971874738e-06, 'lr-AdamW/pg2': 0.0006545084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1075 < 1076; dropping {'train/loss_step': 1.6816432476043701, 'train/acc_step': 0.5, 'epoch': 7}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1075 < 1076; dropping {'lr-AdamW/pg1': 6.545084971874738e-06, 'lr-AdamW/pg2': 0.0006545084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1075 < 1076; dropping {'train/loss_step': 1.4872058629989624, 'train/acc_step': 0.71875, 'epoch': 7}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1075 < 1076; dropping {'lr-AdamW/pg1': 6.545084971874738e-06, 'lr-AdamW/pg2': 0.0006545084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1075 < 1076; dropping {'train/loss_step': 1.6813397407531738, 'train/acc_step': 0.6875, 'epoch': 7}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f40a3756c9045ffab9c31da084302e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1254 < 1255; dropping {'lr-AdamW/pg1': 7.938926261462366e-06, 'lr-AdamW/pg2': 0.0007938926261462366}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1254 < 1255; dropping {'train/loss_step': 1.7587594985961914, 'train/acc_step': 0.6875, 'epoch': 8}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1254 < 1255; dropping {'lr-AdamW/pg1': 7.938926261462366e-06, 'lr-AdamW/pg2': 0.0007938926261462366}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1254 < 1255; dropping {'train/loss_step': 1.7445330619812012, 'train/acc_step': 0.625, 'epoch': 8}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1254 < 1255; dropping {'lr-AdamW/pg1': 7.938926261462366e-06, 'lr-AdamW/pg2': 0.0007938926261462366}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1254 < 1255; dropping {'train/loss_step': 1.6616582870483398, 'train/acc_step': 0.625, 'epoch': 8}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd54cd42d94c45fbb3b2e2442785c5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1433 < 1434; dropping {'lr-AdamW/pg1': 9.045084971874738e-06, 'lr-AdamW/pg2': 0.0009045084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1433 < 1434; dropping {'train/loss_step': 1.661999225616455, 'train/acc_step': 0.65625, 'epoch': 9}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1433 < 1434; dropping {'lr-AdamW/pg1': 9.045084971874738e-06, 'lr-AdamW/pg2': 0.0009045084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1433 < 1434; dropping {'train/loss_step': 1.461803674697876, 'train/acc_step': 0.6875, 'epoch': 9}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1433 < 1434; dropping {'lr-AdamW/pg1': 9.045084971874738e-06, 'lr-AdamW/pg2': 0.0009045084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1433 < 1434; dropping {'train/loss_step': 1.4751070737838745, 'train/acc_step': 0.78125, 'epoch': 9}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250271d7b7464be6bab1fd6c79460517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1612 < 1613; dropping {'lr-AdamW/pg1': 9.755282581475769e-06, 'lr-AdamW/pg2': 0.0009755282581475768}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1612 < 1613; dropping {'train/loss_step': 1.7594172954559326, 'train/acc_step': 0.625, 'epoch': 10}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1612 < 1613; dropping {'lr-AdamW/pg1': 9.755282581475769e-06, 'lr-AdamW/pg2': 0.0009755282581475768}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1612 < 1613; dropping {'train/loss_step': 1.6155195236206055, 'train/acc_step': 0.6875, 'epoch': 10}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1612 < 1613; dropping {'lr-AdamW/pg1': 9.755282581475769e-06, 'lr-AdamW/pg2': 0.0009755282581475768}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1612 < 1613; dropping {'train/loss_step': 1.5021036863327026, 'train/acc_step': 0.65625, 'epoch': 10}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5630df78873941d2bc0512e603ca79db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1791 < 1792; dropping {'lr-AdamW/pg1': 1e-05, 'lr-AdamW/pg2': 0.001}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1791 < 1792; dropping {'train/loss_step': 1.5440902709960938, 'train/acc_step': 0.5625, 'epoch': 11}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1791 < 1792; dropping {'lr-AdamW/pg1': 1e-05, 'lr-AdamW/pg2': 0.001}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1791 < 1792; dropping {'train/loss_step': 1.5446653366088867, 'train/acc_step': 0.59375, 'epoch': 11}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1791 < 1792; dropping {'lr-AdamW/pg1': 1e-05, 'lr-AdamW/pg2': 0.001}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1791 < 1792; dropping {'train/loss_step': 1.3323227167129517, 'train/acc_step': 0.59375, 'epoch': 11}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4bb7cf677c4067837672e52ea88f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1970 < 1971; dropping {'lr-AdamW/pg1': 2.447174185242324e-07, 'lr-AdamW/pg2': 2.4471741852423235e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1970 < 1971; dropping {'train/loss_step': 1.5589752197265625, 'train/acc_step': 0.6875, 'epoch': 12}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1970 < 1971; dropping {'lr-AdamW/pg1': 2.447174185242324e-07, 'lr-AdamW/pg2': 2.4471741852423235e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1970 < 1971; dropping {'train/loss_step': 1.4388246536254883, 'train/acc_step': 0.84375, 'epoch': 12}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1970 < 1971; dropping {'lr-AdamW/pg1': 2.447174185242324e-07, 'lr-AdamW/pg2': 2.4471741852423235e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1970 < 1971; dropping {'train/loss_step': 1.546117901802063, 'train/acc_step': 0.71875, 'epoch': 12}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d433262c9f741d2a843213b6ba7ea53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2149 < 2150; dropping {'lr-AdamW/pg1': 9.549150281252633e-07, 'lr-AdamW/pg2': 9.549150281252633e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2149 < 2150; dropping {'train/loss_step': 1.5257680416107178, 'train/acc_step': 0.59375, 'epoch': 13}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2149 < 2150; dropping {'lr-AdamW/pg1': 9.549150281252633e-07, 'lr-AdamW/pg2': 9.549150281252633e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2149 < 2150; dropping {'train/loss_step': 1.4855331182479858, 'train/acc_step': 0.78125, 'epoch': 13}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2149 < 2150; dropping {'lr-AdamW/pg1': 9.549150281252633e-07, 'lr-AdamW/pg2': 9.549150281252633e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2149 < 2150; dropping {'train/loss_step': 1.5947749614715576, 'train/acc_step': 0.6875, 'epoch': 13}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5c091774d04b12a8c392a86945ee47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2328 < 2329; dropping {'lr-AdamW/pg1': 2.061073738537635e-06, 'lr-AdamW/pg2': 0.00020610737385376348}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2328 < 2329; dropping {'train/loss_step': 1.6107748746871948, 'train/acc_step': 0.6875, 'epoch': 14}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2328 < 2329; dropping {'lr-AdamW/pg1': 2.061073738537635e-06, 'lr-AdamW/pg2': 0.00020610737385376348}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2328 < 2329; dropping {'train/loss_step': 1.3125252723693848, 'train/acc_step': 0.875, 'epoch': 14}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2328 < 2329; dropping {'lr-AdamW/pg1': 2.061073738537635e-06, 'lr-AdamW/pg2': 0.00020610737385376348}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2328 < 2329; dropping {'train/loss_step': 1.401749610900879, 'train/acc_step': 0.875, 'epoch': 14}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcefa9a4b43a4770bd67df7a15ac255a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2507 < 2508; dropping {'lr-AdamW/pg1': 3.4549150281252635e-06, 'lr-AdamW/pg2': 0.00034549150281252633}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2507 < 2508; dropping {'train/loss_step': 1.786037564277649, 'train/acc_step': 0.65625, 'epoch': 15}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2507 < 2508; dropping {'lr-AdamW/pg1': 3.4549150281252635e-06, 'lr-AdamW/pg2': 0.00034549150281252633}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2507 < 2508; dropping {'train/loss_step': 1.5681862831115723, 'train/acc_step': 0.71875, 'epoch': 15}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2507 < 2508; dropping {'lr-AdamW/pg1': 3.4549150281252635e-06, 'lr-AdamW/pg2': 0.00034549150281252633}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2507 < 2508; dropping {'train/loss_step': 1.6750836372375488, 'train/acc_step': 0.75, 'epoch': 15}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b3dacb1d2b439cac9eeb9c9b4ede05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2686 < 2687; dropping {'lr-AdamW/pg1': 5e-06, 'lr-AdamW/pg2': 0.0005}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2686 < 2687; dropping {'train/loss_step': 1.468625545501709, 'train/acc_step': 0.875, 'epoch': 16}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2686 < 2687; dropping {'lr-AdamW/pg1': 5e-06, 'lr-AdamW/pg2': 0.0005}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2686 < 2687; dropping {'train/loss_step': 1.5951200723648071, 'train/acc_step': 0.625, 'epoch': 16}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2686 < 2687; dropping {'lr-AdamW/pg1': 5e-06, 'lr-AdamW/pg2': 0.0005}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2686 < 2687; dropping {'train/loss_step': 1.5832377672195435, 'train/acc_step': 0.78125, 'epoch': 16}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bb6eb277b9419abe4844ac2b216df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2865 < 2866; dropping {'lr-AdamW/pg1': 6.545084971874738e-06, 'lr-AdamW/pg2': 0.0006545084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2865 < 2866; dropping {'train/loss_step': 1.4786264896392822, 'train/acc_step': 0.75, 'epoch': 17}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2865 < 2866; dropping {'lr-AdamW/pg1': 6.545084971874738e-06, 'lr-AdamW/pg2': 0.0006545084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2865 < 2866; dropping {'train/loss_step': 1.390223741531372, 'train/acc_step': 0.8125, 'epoch': 17}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2865 < 2866; dropping {'lr-AdamW/pg1': 6.545084971874738e-06, 'lr-AdamW/pg2': 0.0006545084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2865 < 2866; dropping {'train/loss_step': 1.525599718093872, 'train/acc_step': 0.8125, 'epoch': 17}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24910ff349074faf9bab2317f5d25ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3044 < 3045; dropping {'lr-AdamW/pg1': 7.938926261462366e-06, 'lr-AdamW/pg2': 0.0007938926261462366}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3044 < 3045; dropping {'train/loss_step': 1.49702787399292, 'train/acc_step': 0.71875, 'epoch': 18}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3044 < 3045; dropping {'lr-AdamW/pg1': 7.938926261462366e-06, 'lr-AdamW/pg2': 0.0007938926261462366}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3044 < 3045; dropping {'train/loss_step': 1.3730013370513916, 'train/acc_step': 0.6875, 'epoch': 18}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3044 < 3045; dropping {'lr-AdamW/pg1': 7.938926261462366e-06, 'lr-AdamW/pg2': 0.0007938926261462366}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3044 < 3045; dropping {'train/loss_step': 1.4963178634643555, 'train/acc_step': 0.71875, 'epoch': 18}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a027b8a9c8940028b197fbb8dc27df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3223 < 3224; dropping {'lr-AdamW/pg1': 9.045084971874738e-06, 'lr-AdamW/pg2': 0.0009045084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3223 < 3224; dropping {'train/loss_step': 1.5619075298309326, 'train/acc_step': 0.6875, 'epoch': 19}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3223 < 3224; dropping {'lr-AdamW/pg1': 9.045084971874738e-06, 'lr-AdamW/pg2': 0.0009045084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3223 < 3224; dropping {'train/loss_step': 1.4213199615478516, 'train/acc_step': 0.8125, 'epoch': 19}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3223 < 3224; dropping {'lr-AdamW/pg1': 9.045084971874738e-06, 'lr-AdamW/pg2': 0.0009045084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3223 < 3224; dropping {'train/loss_step': 1.5374177694320679, 'train/acc_step': 0.65625, 'epoch': 19}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81b50057056462b852946ca30d60a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3402 < 3403; dropping {'lr-AdamW/pg1': 9.755282581475769e-06, 'lr-AdamW/pg2': 0.0009755282581475768}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3402 < 3403; dropping {'train/loss_step': 1.3939943313598633, 'train/acc_step': 0.65625, 'epoch': 20}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3402 < 3403; dropping {'lr-AdamW/pg1': 9.755282581475769e-06, 'lr-AdamW/pg2': 0.0009755282581475768}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3402 < 3403; dropping {'train/loss_step': 1.3911795616149902, 'train/acc_step': 0.75, 'epoch': 20}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3402 < 3403; dropping {'lr-AdamW/pg1': 9.755282581475769e-06, 'lr-AdamW/pg2': 0.0009755282581475768}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3402 < 3403; dropping {'train/loss_step': 1.5169868469238281, 'train/acc_step': 0.625, 'epoch': 20}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079da5168397426db2d8d4baa9d2c5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3581 < 3582; dropping {'lr-AdamW/pg1': 1e-05, 'lr-AdamW/pg2': 0.001}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3581 < 3582; dropping {'train/loss_step': 1.49934983253479, 'train/acc_step': 0.65625, 'epoch': 21}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3581 < 3582; dropping {'lr-AdamW/pg1': 1e-05, 'lr-AdamW/pg2': 0.001}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3581 < 3582; dropping {'train/loss_step': 1.5798404216766357, 'train/acc_step': 0.65625, 'epoch': 21}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3581 < 3582; dropping {'lr-AdamW/pg1': 1e-05, 'lr-AdamW/pg2': 0.001}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3581 < 3582; dropping {'train/loss_step': 1.4751964807510376, 'train/acc_step': 0.71875, 'epoch': 21}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959d064b94eb4c70b76c2e801b103abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3760 < 3761; dropping {'lr-AdamW/pg1': 2.447174185242324e-07, 'lr-AdamW/pg2': 2.4471741852423235e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3760 < 3761; dropping {'train/loss_step': 1.531130313873291, 'train/acc_step': 0.78125, 'epoch': 22}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3760 < 3761; dropping {'lr-AdamW/pg1': 2.447174185242324e-07, 'lr-AdamW/pg2': 2.4471741852423235e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3760 < 3761; dropping {'train/loss_step': 1.5147755146026611, 'train/acc_step': 0.53125, 'epoch': 22}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3760 < 3761; dropping {'lr-AdamW/pg1': 2.447174185242324e-07, 'lr-AdamW/pg2': 2.4471741852423235e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3760 < 3761; dropping {'train/loss_step': 1.4672091007232666, 'train/acc_step': 0.6875, 'epoch': 22}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a168c3001ab341f0ba199b08465ff020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3939 < 3940; dropping {'lr-AdamW/pg1': 9.549150281252633e-07, 'lr-AdamW/pg2': 9.549150281252633e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3939 < 3940; dropping {'train/loss_step': 1.4314351081848145, 'train/acc_step': 0.65625, 'epoch': 23}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3939 < 3940; dropping {'lr-AdamW/pg1': 9.549150281252633e-07, 'lr-AdamW/pg2': 9.549150281252633e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3939 < 3940; dropping {'train/loss_step': 1.5669951438903809, 'train/acc_step': 0.65625, 'epoch': 23}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3939 < 3940; dropping {'lr-AdamW/pg1': 9.549150281252633e-07, 'lr-AdamW/pg2': 9.549150281252633e-05}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3939 < 3940; dropping {'train/loss_step': 1.4506306648254395, 'train/acc_step': 0.78125, 'epoch': 23}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1de046c6cb419a93f206d6856b759f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4118 < 4119; dropping {'lr-AdamW/pg1': 2.061073738537635e-06, 'lr-AdamW/pg2': 0.00020610737385376348}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4118 < 4119; dropping {'train/loss_step': 1.4361999034881592, 'train/acc_step': 0.6875, 'epoch': 24}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4118 < 4119; dropping {'lr-AdamW/pg1': 2.061073738537635e-06, 'lr-AdamW/pg2': 0.00020610737385376348}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4118 < 4119; dropping {'train/loss_step': 1.4448857307434082, 'train/acc_step': 0.625, 'epoch': 24}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4118 < 4119; dropping {'lr-AdamW/pg1': 2.061073738537635e-06, 'lr-AdamW/pg2': 0.00020610737385376348}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4118 < 4119; dropping {'train/loss_step': 1.5325572490692139, 'train/acc_step': 0.71875, 'epoch': 24}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2169a4f18144c3da43c4cae920785c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4297 < 4298; dropping {'lr-AdamW/pg1': 3.4549150281252635e-06, 'lr-AdamW/pg2': 0.00034549150281252633}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4297 < 4298; dropping {'train/loss_step': 1.6304645538330078, 'train/acc_step': 0.6875, 'epoch': 25}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4297 < 4298; dropping {'lr-AdamW/pg1': 3.4549150281252635e-06, 'lr-AdamW/pg2': 0.00034549150281252633}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4297 < 4298; dropping {'train/loss_step': 1.381197214126587, 'train/acc_step': 0.78125, 'epoch': 25}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4297 < 4298; dropping {'lr-AdamW/pg1': 3.4549150281252635e-06, 'lr-AdamW/pg2': 0.00034549150281252633}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4297 < 4298; dropping {'train/loss_step': 1.515650749206543, 'train/acc_step': 0.625, 'epoch': 25}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a7e1b883fe4b94a4f06b28964efa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4476 < 4477; dropping {'lr-AdamW/pg1': 5e-06, 'lr-AdamW/pg2': 0.0005}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4476 < 4477; dropping {'train/loss_step': 1.3170220851898193, 'train/acc_step': 0.78125, 'epoch': 26}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4476 < 4477; dropping {'lr-AdamW/pg1': 5e-06, 'lr-AdamW/pg2': 0.0005}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4476 < 4477; dropping {'train/loss_step': 1.7811986207962036, 'train/acc_step': 0.5625, 'epoch': 26}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4476 < 4477; dropping {'lr-AdamW/pg1': 5e-06, 'lr-AdamW/pg2': 0.0005}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4476 < 4477; dropping {'train/loss_step': 1.6817737817764282, 'train/acc_step': 0.625, 'epoch': 26}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc385e35e0f0465b9bc832d4cf48ca60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4655 < 4656; dropping {'lr-AdamW/pg1': 6.545084971874738e-06, 'lr-AdamW/pg2': 0.0006545084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4655 < 4656; dropping {'train/loss_step': 1.4018418788909912, 'train/acc_step': 0.8125, 'epoch': 27}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4655 < 4656; dropping {'lr-AdamW/pg1': 6.545084971874738e-06, 'lr-AdamW/pg2': 0.0006545084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4655 < 4656; dropping {'train/loss_step': 1.5579805374145508, 'train/acc_step': 0.65625, 'epoch': 27}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4655 < 4656; dropping {'lr-AdamW/pg1': 6.545084971874738e-06, 'lr-AdamW/pg2': 0.0006545084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4655 < 4656; dropping {'train/loss_step': 1.9395077228546143, 'train/acc_step': 0.4375, 'epoch': 27}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8ad96a594343c0818e9f2fab79be2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4834 < 4835; dropping {'lr-AdamW/pg1': 7.938926261462366e-06, 'lr-AdamW/pg2': 0.0007938926261462366}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4834 < 4835; dropping {'train/loss_step': 1.5669538974761963, 'train/acc_step': 0.6875, 'epoch': 28}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4834 < 4835; dropping {'lr-AdamW/pg1': 7.938926261462366e-06, 'lr-AdamW/pg2': 0.0007938926261462366}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4834 < 4835; dropping {'train/loss_step': 1.5259389877319336, 'train/acc_step': 0.71875, 'epoch': 28}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4834 < 4835; dropping {'lr-AdamW/pg1': 7.938926261462366e-06, 'lr-AdamW/pg2': 0.0007938926261462366}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4834 < 4835; dropping {'train/loss_step': 1.5194671154022217, 'train/acc_step': 0.65625, 'epoch': 28}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf81e4b5e07b4b8085ec964991bbf141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5013 < 5014; dropping {'lr-AdamW/pg1': 9.045084971874738e-06, 'lr-AdamW/pg2': 0.0009045084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5013 < 5014; dropping {'train/loss_step': 1.67506742477417, 'train/acc_step': 0.53125, 'epoch': 29}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5013 < 5014; dropping {'lr-AdamW/pg1': 9.045084971874738e-06, 'lr-AdamW/pg2': 0.0009045084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5013 < 5014; dropping {'train/loss_step': 1.4566072225570679, 'train/acc_step': 0.65625, 'epoch': 29}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5013 < 5014; dropping {'lr-AdamW/pg1': 9.045084971874738e-06, 'lr-AdamW/pg2': 0.0009045084971874737}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5013 < 5014; dropping {'train/loss_step': 1.4555819034576416, 'train/acc_step': 0.75, 'epoch': 29}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39eb021b7ef746b69222b004d4d870bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify the initial learning rate \n",
    "litModel.hparams['lr'] = 1e-03\n",
    "\n",
    "# start the training job\n",
    "trainer.fit(litModel, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076813430a4844fbb198435887e8dee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5192 < 5193; dropping {'valid/loss': 0.8122750520706177, 'valid/acc': 0.7964953184127808, 'test/acc': 0.7964953184127808, 'test/loss': 0.8122750520706177, 'epoch': 29}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/acc': tensor(0.7965, device='cuda:0'),\n",
      " 'test/loss': tensor(0.8123, device='cuda:0'),\n",
      " 'train/acc': tensor(0.6897, device='cuda:0'),\n",
      " 'train/acc_epoch': tensor(0.7120, device='cuda:0'),\n",
      " 'train/acc_step': tensor(0.6897, device='cuda:0'),\n",
      " 'train/loss': tensor(1.5469, device='cuda:0'),\n",
      " 'train/loss_epoch': tensor(1.5101, device='cuda:0'),\n",
      " 'train/loss_step': tensor(1.5469, device='cuda:0'),\n",
      " 'valid/acc': tensor(0.7965, device='cuda:0'),\n",
      " 'valid/loss': tensor(0.8123, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# automatically loads in the best model weights\n",
    "# according to metric in checkpoint callback\n",
    "results = trainer.test(litModel, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weights saved to resnext50_32x4d-fold=0-1f25c028.pt\n"
     ]
    }
   ],
   "source": [
    "# save the weights of the model\n",
    "litModel.save_model_weights(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 295<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf2c141d5994521b2c72704e489f64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 106.89MB of 194.96MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.5482664…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20201226_213308-179br06w/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20201226_213308-179br06w/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>lr-AdamW/pg1</td><td>1e-05</td></tr><tr><td>lr-AdamW/pg2</td><td>0.001</td></tr><tr><td>train/loss_step</td><td>1.54694</td></tr><tr><td>train/acc_step</td><td>0.68966</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>_step</td><td>5192</td></tr><tr><td>_runtime</td><td>19097</td></tr><tr><td>_timestamp</td><td>1609037485</td></tr><tr><td>valid/loss</td><td>0.81228</td></tr><tr><td>valid/acc</td><td>0.7965</td></tr><tr><td>train/loss_epoch</td><td>1.51007</td></tr><tr><td>train/acc_epoch</td><td>0.71198</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>lr-AdamW/pg1</td><td>▇▇█▁▂▃▄▆▇██▁▂▃▄▆▇██▁▂▃▄▇▇██▂▂▃▆▇▇█▁▂▂▄▆▂</td></tr><tr><td>lr-AdamW/pg2</td><td>▇▇█▁▂▃▄▆▇██▁▂▃▄▆▇██▁▂▃▄▇▇██▂▂▃▆▇▇█▁▂▂▄▆▂</td></tr><tr><td>train/loss_step</td><td>▇▄▆▅▅▅▅▂▃▇▅▅▄▃█▃▅▂▃█▄▄▄▂▃█▃▄▄▄▇▄▂▄▅▇▁▅▆▅</td></tr><tr><td>train/acc_step</td><td>▃▅▃▆▆▂▆▆▇▂▅▄▅▄▄▆▇▆▅▃▇▅▅▅▅▃▇▇▄▃▁▅▅▆▄▂█▄▄▅</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▃▃▂▂▂▁▂▂▁▁▂▁▂▂▁▁▁</td></tr><tr><td>valid/acc</td><td>▁▂▆▅▅▆▇▇▇▇▇▇▆▅▇█▇█▇██▇▇▇▇███▇</td></tr><tr><td>train/loss_epoch</td><td>█▄▄▃▂▃▃▂▂▂▃▂▂▂▂▂▁▃▂▁▂▁▁▂▂▂▁▁▁</td></tr><tr><td>train/acc_epoch</td><td>▁▃▄▅▅▆▅▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 262 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">young-shadow-6</strong>: <a href=\"https://wandb.ai/ayushman/kaggle-leaf-disease-v2/runs/179br06w\" target=\"_blank\">https://wandb.ai/ayushman/kaggle-leaf-disease-v2/runs/179br06w</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# upload model weights to wandb server and\n",
    "# finish the wandb run\n",
    "wandb.save(MODEL_SAVE_PATH)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
