{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Training Notebook from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üöÄ Installing and importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'leaf-disease-classification-kaggle'...\r\n",
      "remote: Enumerating objects: 77, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (77/77), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (58/58), done.\u001b[K\r\n",
      "remote: Total 1329 (delta 37), reused 51 (delta 19), pack-reused 1252\u001b[K\r\n",
      "Receiving objects: 100% (1329/1329), 43.77 MiB | 29.18 MiB/s, done.\r\n",
      "Resolving deltas: 100% (751/751), done.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/benihime91/leaf-disease-classification-kaggle.git\n",
    "\n",
    "!wandb login a74f67fd5fae293e301ea8b6710ee0241f595a63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timmmodels/pytorch-image-models/')\n",
    "sys.path.append('leaf-disease-classification-kaggle/')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from fastai.torch_core import apply_init\n",
    "from functools import partial\n",
    "import wandb\n",
    "\n",
    "from src.core import *\n",
    "from src.lightning.core import *\n",
    "from src.layers import *\n",
    "from src.mixmethods import *\n",
    "from src.networks import *\n",
    "\n",
    "logger = logging.getLogger(\"wandb\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**set random seeds so that results are reproducible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = seed_everything(42)\n",
    "idx  = generate_random_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ‚ö° üíò üèãÔ∏è‚Äç‚ôÄÔ∏è Configure the Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure the training paramters/job\n",
    "config = dict(\n",
    "    random_seed = seed,\n",
    "    unique_idx = idx,\n",
    "    project_name = \"kaggle-leaf-disease-v2\",\n",
    "    \n",
    "    curr_fold = 0,\n",
    "    image_dir = \"../input/cassava-leaf-disease-classification/train_images/\",\n",
    "    csv_path = \"leaf-disease-classification-kaggle/data/stratified-data-5folds.csv\",\n",
    "    \n",
    "    encoder = \"seresnext50_32x4d\",\n",
    "    activation = dict(type='torch.nn.ReLU', inplace=True),\n",
    "    \n",
    "    image_dims = 512,\n",
    "    num_epochs = 40,\n",
    "    batch_size = 32,\n",
    "    accumulate_batches = 1,\n",
    "    clip_grad_norm = 0.5,\n",
    "    )\n",
    "\n",
    "hparams = dict(\n",
    "    mixmethod = dict(type='src.mixmethods.SnapMix', alpha=5.0, conf_prob=1.0),\n",
    "    loss_function = dict(type='src.core.LabelSmoothingCrossEntropy', eps=0.1),\n",
    "    \n",
    "    learning_rate = 1e-03,\n",
    "    lr_mult = 100,\n",
    "    \n",
    "    optimizer = dict(type='torch.optim.AdamW', betas=(0.9, 0.99), eps=1e-06, weight_decay=1e-03),\n",
    "    \n",
    "    scheduler = dict(type='torch.optim.lr_scheduler.CosineAnnealingWarmRestarts', T_0=10, T_mult=2),\n",
    "    \n",
    "    metric_to_track = None,\n",
    "    step_after = \"step\",\n",
    "    frequency = 1,\n",
    "    )\n",
    "\n",
    "\n",
    "# Albumentations augmentations for train/ valid data\n",
    "TRAIN_AUGS = A.Compose([\n",
    "    A.RandomResizedCrop(config[\"image_dims\"], config[\"image_dims\"], p=0.5), \n",
    "    A.Resize(config[\"image_dims\"], config[\"image_dims\"], p=1.0),\n",
    "    A.HorizontalFlip(),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
    "    A.CoarseDropout(p=0.5),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0)\n",
    "])\n",
    "    \n",
    "VALID_AUGS = A.Compose([\n",
    "    A.Resize(config[\"image_dims\"], config[\"image_dims\"], p=1.0), \n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "\n",
    "MODEL_SAVE_PATH = f\"{config['encoder']}-fold={config['curr_fold']}-{idx}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üèóÔ∏è Building a Model with Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext50_32x4d_racm-a304a460.pth\" to /root/.cache/torch/hub/checkpoints/seresnext50_32x4d_racm-a304a460.pth\n"
     ]
    }
   ],
   "source": [
    "# initate the model architecture\n",
    "# for snapmix we will call BasicTransferLearningModel class to init a model\n",
    "# suitable for snapmix, we can also use TransferLearningModel class to init\n",
    "# a model similar to the model created by the fast.ai cnn_learner func\n",
    "\n",
    "encoder = timm.create_model(config[\"encoder\"], pretrained=True)\n",
    "\n",
    "model = SnapMixTransferLearningModel(\n",
    "    encoder=encoder, \n",
    "    c=len(idx2lbl), \n",
    "    cut=-2, \n",
    "    act=object_from_dict(config[\"activation\"]),)\n",
    "\n",
    "# init the weights of the final untrained layer\n",
    "apply_init(model.fc, torch.nn.init.kaiming_normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mixmethod : SnapMix\n",
      "Loss Function : LabelSmoothingCrossEntropy()\n"
     ]
    }
   ],
   "source": [
    "litModel = LightningCassava(model=model, conf=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightningCassava(\n",
      "  (model): SnapMixTransferLearningModel(\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
      "  )\n",
      "  (loss_func): LabelSmoothingCrossEntropy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(litModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üõí Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init the LightingDataModule + LightningModule\n",
    "dm = CassavaLightningDataModule(config[\"csv_path\"], config[\"image_dir\"], \n",
    "                                curr_fold=config[\"curr_fold\"], \n",
    "                                train_augs=TRAIN_AUGS, \n",
    "                                valid_augs=VALID_AUGS, \n",
    "                                bs=config[\"batch_size\"], \n",
    "                                num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üì≤ Callbacks ‚ûï Optional methods for even better logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize pytorch_lightning Trainer + Callbacks\n",
    "callbacks = [\n",
    "    pl.callbacks.LearningRateMonitor(\"step\"), \n",
    "    WandbImageClassificationCallback(dm, default_config=config),\n",
    "    pl.callbacks.EarlyStopping(monitor=\"valid/acc\", patience=5, mode=\"max\")\n",
    "]\n",
    "\n",
    "chkpt_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=\"valid/acc\",\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    "    filename=MODEL_SAVE_PATH)\n",
    "\n",
    "wb_logger = pl.loggers.WandbLogger(project=config[\"project_name\"], log_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üëü Making a Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=-1, \n",
    "    precision=16,\n",
    "    checkpoint_callback=chkpt_callback, logger=wb_logger,\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=config[\"num_epochs\"],\n",
    "    gradient_clip_val=config[\"clip_grad_norm\"], \n",
    "    accumulate_grad_batches=config[\"accumulate_batches\"],\n",
    "    log_every_n_steps=1,\n",
    "    deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # start learning_rate finder to find optimum starting Lr\n",
    "# lr_finder = trainer.tuner.lr_find(litModel, datamodule=dm)\n",
    "\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üèÉ‚Äç‚ôÄÔ∏è Running our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data for fold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mayushman\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">expert-snow-26</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ayushman/kaggle-leaf-disease-v2\" target=\"_blank\">https://wandb.ai/ayushman/kaggle-leaf-disease-v2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ayushman/kaggle-leaf-disease-v2/runs/3nzk2h0v\" target=\"_blank\">https://wandb.ai/ayushman/kaggle-leaf-disease-v2/runs/3nzk2h0v</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20201227_133732-3nzk2h0v</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type                         | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model     | SnapMixTransferLearningModel | 25.5 M\n",
      "1 | loss_func | LabelSmoothingCrossEntropy   | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5012c148e634d10938623e3b5fb3df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb config updated -->\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cfed006f17402eb4f500f43990f46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e15ee863c1459eb66ebb0879fb3711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190e87307222452e9f8c7bd08957a0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb066a93ea67402ba2c0081816b01725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92822179498944609a61397d04638537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edd1cce25ed4b529943d262e4068ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636edfd5b26c4a288976b43908b51765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 0 file into the W&B run directory, call wandb.save again to sync new files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify the initial learning rate \n",
    "litModel.hparams['learning_rate'] = 8e-04\n",
    "\n",
    "# start the training job\n",
    "trainer.fit(litModel, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üíæ Testing and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdede97040d497493d74f509764bbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/acc': tensor(0.7832, device='cuda:0'),\n",
      " 'test/loss': tensor(0.8497, device='cuda:0'),\n",
      " 'train/acc': tensor(0.5862, device='cuda:0'),\n",
      " 'train/acc_epoch': tensor(0.6871, device='cuda:0'),\n",
      " 'train/acc_step': tensor(0.5862, device='cuda:0'),\n",
      " 'train/loss': tensor(1.4827, device='cuda:0'),\n",
      " 'train/loss_epoch': tensor(1.5427, device='cuda:0'),\n",
      " 'train/loss_step': tensor(1.4827, device='cuda:0'),\n",
      " 'valid/acc': tensor(0.7832, device='cuda:0'),\n",
      " 'valid/loss': tensor(0.8497, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# automatically loads in the best model weights\n",
    "# according to metric in checkpoint callback\n",
    "results = trainer.test(datamodule=dm, ckpt_path=None) # uses last-saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weights saved to seresnext50_32x4d-fold=0-a5f87938.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/wandb/run-20201227_133732-3nzk2h0v/files/seresnext50_32x4d-fold=0-a5f87938.pt']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = f\"{MODEL_SAVE_PATH}.pt\"\n",
    "# save the weights of the model\n",
    "litModel.save_model_weights(path)\n",
    "wandb.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 77<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d93ea6a4564856bbb8239ac2cf4ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 45.46MB of 45.46MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20201227_133732-3nzk2h0v/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20201227_133732-3nzk2h0v/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>lr-AdamW/pg1</td><td>1e-05</td></tr><tr><td>lr-AdamW/pg2</td><td>0.00068</td></tr><tr><td>train/loss_step</td><td>1.48269</td></tr><tr><td>train/acc_step</td><td>0.58621</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>_step</td><td>6419</td></tr><tr><td>_runtime</td><td>4578</td></tr><tr><td>_timestamp</td><td>1609080830</td></tr><tr><td>valid/loss</td><td>0.84973</td></tr><tr><td>valid/acc</td><td>0.78318</td></tr><tr><td>train/loss_epoch</td><td>1.54266</td></tr><tr><td>train/acc_epoch</td><td>0.68714</td></tr><tr><td>test/acc</td><td>0.78318</td></tr><tr><td>test/loss</td><td>0.84973</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>lr-AdamW/pg1</td><td>‚ñà‚ñÜ‚ñá‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>lr-AdamW/pg2</td><td>‚ñà‚ñÜ‚ñá‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>train/loss_step</td><td>‚ñá‚ñà‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÇ</td></tr><tr><td>train/acc_step</td><td>‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÉ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>_runtime</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>_timestamp</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>valid/loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>valid/acc</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train/loss_epoch</td><td>‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>train/acc_epoch</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>test/acc</td><td>‚ñÅ</td></tr><tr><td>test/loss</td><td>‚ñÅ</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 103 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">expert-snow-26</strong>: <a href=\"https://wandb.ai/ayushman/kaggle-leaf-disease-v2/runs/3nzk2h0v\" target=\"_blank\">https://wandb.ai/ayushman/kaggle-leaf-disease-v2/runs/3nzk2h0v</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finish the experiment\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
