{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "colab-demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "9MYmjDlmQjPH"
      },
      "source": [
        "Training Notebook from Google-colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "tqQa6qzQQjPQ"
      },
      "source": [
        "# üöÄ Installing and importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCy7URPyWLdI"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBep7qf8UEQW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OrN6W_4QwYM"
      },
      "source": [
        "# Ensure colab doesn't disconnect\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br1EFH82Q1y_"
      },
      "source": [
        "!unzip -qq '/content/drive/MyDrive/cassava-leaf-disease-classification.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY8MBqhHQrNt"
      },
      "source": [
        "!pip install --upgrade wandb albumentations pytorch-lightning timm --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "RjsAK_YaQjPS"
      },
      "source": [
        "!git clone https://github.com/benihime91/leaf-disease-classification-kaggle.git\n",
        "\n",
        "!wandb login a74f67fd5fae293e301ea8b6710ee0241f595a63"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "rVbULlQVQjPT"
      },
      "source": [
        "import sys\n",
        "#sys.path.append('../input/timmmodels/pytorch-image-models/')\n",
        "sys.path.append(\"/content/leaf-disease-classification-kaggle\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "vzkjlv4YQjPU"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from fastai.torch_core import apply_init\n",
        "from functools import partial\n",
        "import wandb\n",
        "\n",
        "from src.core import *\n",
        "from src.lightning.core import *\n",
        "from src.layers import *\n",
        "from src.mixmethods import *\n",
        "from src.networks import *\n",
        "\n",
        "logger = logging.getLogger(\"wandb\")\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "52DsdR-3QjPV"
      },
      "source": [
        "**set random seeds so that results are reproducible**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HL6oPJ_eQjPV"
      },
      "source": [
        "seed = seed_everything(42)\n",
        "idx  = generate_random_id()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "AfAvLYKBQjPV"
      },
      "source": [
        "# ‚ö° üíò üèãÔ∏è‚Äç‚ôÄÔ∏è Configure the Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "aR9hGMOUQjPW"
      },
      "source": [
        "# configure the training paramters/job\n",
        "config = dict(\n",
        "    random_seed = seed,\n",
        "    unique_idx = idx,\n",
        "    project_name = \"kaggle-leaf-disease-v2\",\n",
        "    \n",
        "    curr_fold = 0,\n",
        "    image_dir = \"cassava-leaf-disease-classification/train_images/\",\n",
        "    csv_path = \"leaf-disease-classification-kaggle/data/stratified-data-5folds.csv\",\n",
        "    \n",
        "    encoder = \"tf_efficientnet_b3_ns\",\n",
        "    activation = dict(type='src.layers.Mish'),\n",
        "    \n",
        "    image_dims = 512,\n",
        "    num_epochs = 30,\n",
        "    batch_size = 32,\n",
        "    accumulate_batches = 1,\n",
        "    clip_grad_norm = 0.1\n",
        "    )\n",
        "\n",
        "hparams = dict(\n",
        "    mixmethod = dict(type='src.mixmethods.Mixup', alpha=0.5),\n",
        "    loss_function = dict(type='src.core.LabelSmoothingCrossEntropy', eps=0.1),\n",
        "    \n",
        "    learning_rate = 1e-03,\n",
        "    lr_mult = 100,\n",
        "    \n",
        "    optimizer = dict(type='torch.optim.Adam', betas=(0.9, 0.99), eps=1e-06, weight_decay=1e-06),\n",
        "    \n",
        "    scheduler = dict(type='torch.optim.lr_scheduler.CosineAnnealingWarmRestarts', T_0=10, T_mult=2),\n",
        "    \n",
        "    metric_to_track = None,\n",
        "    step_after = \"step\",\n",
        "    frequency = 1,\n",
        "    )\n",
        "\n",
        "\n",
        "# Albumentations augmentations for train/ valid data\n",
        "TRAIN_AUGS = A.Compose([\n",
        "    A.OneOf([\n",
        "        A.RandomResizedCrop(config[\"image_dims\"], config[\"image_dims\"]), \n",
        "        A.CenterCrop(config[\"image_dims\"], config[\"image_dims\"])], \n",
        "    p=0.7),\n",
        "    A.Resize(config[\"image_dims\"], config[\"image_dims\"], p=1.0),\n",
        "    A.OneOf([A.ShiftScaleRotate(), A.HorizontalFlip(), A.Transpose()], p=0.8),\n",
        "    A.OneOf([A.RandomBrightnessContrast(0.1, 0.1), A.HueSaturationValue(20, 20, 20)], p=0.5),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "    A.CoarseDropout(p=0.5),\n",
        "    ToTensorV2(p=1.0),\n",
        "])\n",
        "    \n",
        "VALID_AUGS = A.Compose([\n",
        "    A.CenterCrop(config[\"image_dims\"], config[\"image_dims\"], p=1.0),\n",
        "    A.Resize(config[\"image_dims\"], config[\"image_dims\"], p=1.0), \n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "    ToTensorV2(p=1.0),\n",
        "])\n",
        "\n",
        "MODEL_SAVE_PATH = f\"{config['encoder']}-fold={config['curr_fold']}-{idx}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "7LEpKPryQjPW"
      },
      "source": [
        "# üèóÔ∏è Building a Model with Lightning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "FRJpVgMJQjPX"
      },
      "source": [
        "# initate the model architecture\n",
        "# for snapmix we will call BasicTransferLearningModel class to init a model\n",
        "# suitable for snapmix, we can also use TransferLearningModel class to init\n",
        "# a model similar to the model created by the fast.ai cnn_learner func\n",
        "\n",
        "encoder = timm.create_model(config[\"encoder\"], pretrained=True)\n",
        "\n",
        "model = TransferLearningModel(\n",
        "    encoder, \n",
        "    cut=-2, \n",
        "    c=len(idx2lbl), \n",
        "    act=object_from_dict(config[\"activation\"]))\n",
        "\n",
        "# replace all the model activations\n",
        "replace_activs(model.encoder, func=object_from_dict(config[\"activation\"]))\n",
        "\n",
        "# init the weights of the final untrained layer\n",
        "apply_init(model.fc, torch.nn.init.kaiming_normal_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "kRNeY0PHQjPX"
      },
      "source": [
        "litModel = LightningCassava(model=model, conf=hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "wlHdql1WQjPY"
      },
      "source": [
        "print(litModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "MHUEyt2VQjPY"
      },
      "source": [
        "# üõí Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "N51All-bQjPZ"
      },
      "source": [
        "# init the LightingDataModule + LightningModule\n",
        "dm = CassavaLightningDataModule(config[\"csv_path\"], config[\"image_dir\"], \n",
        "                                curr_fold=config[\"curr_fold\"], \n",
        "                                train_augs=TRAIN_AUGS, \n",
        "                                valid_augs=VALID_AUGS, \n",
        "                                bs=config[\"batch_size\"], \n",
        "                                num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "S7UydujcQjPZ"
      },
      "source": [
        "# üì≤ Callbacks ‚ûï Optional methods for even better logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "briX27KYQjPa"
      },
      "source": [
        "# initialize pytorch_lightning Trainer + Callbacks\n",
        "callbacks = [\n",
        "    pl.callbacks.LearningRateMonitor(\"step\"), \n",
        "    WandbImageClassificationCallback(dm, default_config=config),]\n",
        "\n",
        "chkpt_callback = pl.callbacks.ModelCheckpoint(\n",
        "    monitor=\"valid/acc\",\n",
        "    save_top_k=1,\n",
        "    mode='max',\n",
        "    filename=MODEL_SAVE_PATH)\n",
        "\n",
        "wb_logger = pl.loggers.WandbLogger(project=config[\"project_name\"], log_model=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "MHwIljAcQjPa"
      },
      "source": [
        "# üëü Making a Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Os5IPGSKQjPa"
      },
      "source": [
        "trainer = pl.Trainer(\n",
        "    gpus=-1, \n",
        "    precision=16,\n",
        "    checkpoint_callback=chkpt_callback, logger=wb_logger,\n",
        "    callbacks=callbacks,\n",
        "    max_epochs=config[\"num_epochs\"],\n",
        "    gradient_clip_val=config[\"clip_grad_norm\"], \n",
        "    accumulate_grad_batches=config[\"accumulate_batches\"],\n",
        "    log_every_n_steps=1,\n",
        "    deterministic=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Ew_2gaddQjPb"
      },
      "source": [
        "# start learning_rate finder to find optimum starting Lr\n",
        "lr_finder = trainer.tuner.lr_find(litModel, datamodule=dm)\n",
        "\n",
        "fig = lr_finder.plot(suggest=True)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "TgeLCWugQjPb"
      },
      "source": [
        "# üèÉ‚Äç‚ôÄÔ∏è Running our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "21cNXveSQjPb"
      },
      "source": [
        "# modify the initial learning rate \n",
        "litModel.hparams['learning_rate'] = 1e-03\n",
        "\n",
        "# start the training job\n",
        "trainer.fit(litModel, datamodule=dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "I49AY0sAQjPc"
      },
      "source": [
        "# üíæ Testing and saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "iTAKHMnRQjPc"
      },
      "source": [
        "# automatically loads in the best model weights\n",
        "# according to metric in checkpoint callback\n",
        "results = trainer.test(datamodule=dm, ckpt_path=None) # uses last-saved model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "n8so8OduQjPc"
      },
      "source": [
        "path = f\"{MODEL_SAVE_PATH}.pt\"\n",
        "# save the weights of the model\n",
        "litModel.save_model_weights(path)\n",
        "wandb.save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "FVfQ1W2pQjPd"
      },
      "source": [
        "# finish the experiment\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}