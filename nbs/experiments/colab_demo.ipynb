{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Training Notebook from Google-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üöÄ Installing and importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure colab doesn't disconnect\n",
    "%%javascript\n",
    "function ClickConnect(){\n",
    "console.log(\"Working\");\n",
    "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
    "}setInterval(ClickConnect,60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq '/content/drive/MyDrive/cassava-leaf-disease-classification.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade wandb albumentations pytorch-lightning timm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/benihime91/leaf-disease-classification-kaggle.git\n",
    "\n",
    "!wandb login a74f67fd5fae293e301ea8b6710ee0241f595a63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('../input/timmmodels/pytorch-image-models/')\n",
    "sys.path.append(\"/content/leaf-disease-classification-kaggle\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from fastai.torch_core import apply_init\n",
    "from functools import partial\n",
    "import wandb\n",
    "\n",
    "from src.core import *\n",
    "from src.lightning.core import *\n",
    "from src.layers import *\n",
    "from src.mixmethods import *\n",
    "from src.networks import *\n",
    "\n",
    "logger = logging.getLogger(\"wandb\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**set random seeds so that results are reproducible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = seed_everything(42)\n",
    "idx  = generate_random_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ‚ö° üíò üèãÔ∏è‚Äç‚ôÄÔ∏è Configure the Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure the training paramters/job\n",
    "config = dict(\n",
    "    random_seed = seed,\n",
    "    unique_idx = idx,\n",
    "    project_name = \"kaggle-leaf-disease-v2\",\n",
    "    \n",
    "    curr_fold = 0,\n",
    "    image_dir = \"cassava-leaf-disease-classification/train_images/\",\n",
    "    csv_path = \"leaf-disease-classification-kaggle/data/stratified-data-5folds.csv\",\n",
    "    \n",
    "    encoder = \"tf_efficientnet_b3_ns\",\n",
    "    activation = dict(type='src.layers.Mish'),\n",
    "    \n",
    "    image_dims = 512,\n",
    "    num_epochs = 30,\n",
    "    batch_size = 32,\n",
    "    accumulate_batches = 1,\n",
    "    clip_grad_norm = 0.1\n",
    "    )\n",
    "\n",
    "hparams = dict(\n",
    "    mixmethod = dict(type='src.mixmethods.Mixup', alpha=0.5),\n",
    "    loss_function = dict(type='src.core.LabelSmoothingCrossEntropy', eps=0.1),\n",
    "    \n",
    "    learning_rate = 1e-03,\n",
    "    lr_mult = 100,\n",
    "    \n",
    "    optimizer = dict(type='torch.optim.Adam', betas=(0.9, 0.99), eps=1e-06, weight_decay=1e-06),\n",
    "    \n",
    "    scheduler = dict(type='torch.optim.lr_scheduler.CosineAnnealingWarmRestarts', T_0=10, T_mult=2),\n",
    "    \n",
    "    metric_to_track = None,\n",
    "    step_after = \"step\",\n",
    "    frequency = 1,\n",
    "    )\n",
    "\n",
    "\n",
    "# Albumentations augmentations for train/ valid data\n",
    "TRAIN_AUGS = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomResizedCrop(config[\"image_dims\"], config[\"image_dims\"]), \n",
    "        A.CenterCrop(config[\"image_dims\"], config[\"image_dims\"])], \n",
    "    p=0.7),\n",
    "    A.Resize(config[\"image_dims\"], config[\"image_dims\"], p=1.0),\n",
    "    A.OneOf([A.ShiftScaleRotate(), A.HorizontalFlip(), A.Transpose()], p=0.8),\n",
    "    A.OneOf([A.RandomBrightnessContrast(0.1, 0.1), A.HueSaturationValue(20, 20, 20)], p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "    A.CoarseDropout(p=0.5),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "    \n",
    "VALID_AUGS = A.Compose([\n",
    "    A.CenterCrop(config[\"image_dims\"], config[\"image_dims\"], p=1.0),\n",
    "    A.Resize(config[\"image_dims\"], config[\"image_dims\"], p=1.0), \n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "\n",
    "MODEL_SAVE_PATH = f\"{config['encoder']}-fold={config['curr_fold']}-{idx}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üèóÔ∏è Building a Model with Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initate the model architecture\n",
    "# for snapmix we will call BasicTransferLearningModel class to init a model\n",
    "# suitable for snapmix, we can also use TransferLearningModel class to init\n",
    "# a model similar to the model created by the fast.ai cnn_learner func\n",
    "\n",
    "encoder = timm.create_model(config[\"encoder\"], pretrained=True)\n",
    "\n",
    "model = TransferLearningModel(\n",
    "    encoder, \n",
    "    cut=-2, \n",
    "    c=len(idx2lbl), \n",
    "    act=object_from_dict(config[\"activation\"]))\n",
    "\n",
    "# replace all the model activations\n",
    "replace_activs(model.encoder, func=object_from_dict(config[\"activation\"]))\n",
    "\n",
    "# init the weights of the final untrained layer\n",
    "apply_init(model.fc, torch.nn.init.kaiming_normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "litModel = LightningCassava(model=model, conf=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(litModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üõí Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init the LightingDataModule + LightningModule\n",
    "dm = CassavaLightningDataModule(config[\"csv_path\"], config[\"image_dir\"], \n",
    "                                curr_fold=config[\"curr_fold\"], \n",
    "                                train_augs=TRAIN_AUGS, \n",
    "                                valid_augs=VALID_AUGS, \n",
    "                                bs=config[\"batch_size\"], \n",
    "                                num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üì≤ Callbacks ‚ûï Optional methods for even better logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize pytorch_lightning Trainer + Callbacks\n",
    "callbacks = [\n",
    "    pl.callbacks.LearningRateMonitor(\"step\"), \n",
    "    WandbImageClassificationCallback(dm, default_config=config),]\n",
    "\n",
    "chkpt_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=\"valid/acc\",\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    "    filename=MODEL_SAVE_PATH)\n",
    "\n",
    "wb_logger = pl.loggers.WandbLogger(project=config[\"project_name\"], log_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üëü Making a Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=-1, \n",
    "    precision=16,\n",
    "    checkpoint_callback=chkpt_callback, logger=wb_logger,\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=config[\"num_epochs\"],\n",
    "    gradient_clip_val=config[\"clip_grad_norm\"], \n",
    "    accumulate_grad_batches=config[\"accumulate_batches\"],\n",
    "    log_every_n_steps=1,\n",
    "    deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start learning_rate finder to find optimum starting Lr\n",
    "lr_finder = trainer.tuner.lr_find(litModel, datamodule=dm)\n",
    "\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üèÉ‚Äç‚ôÄÔ∏è Running our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modify the initial learning rate \n",
    "litModel.hparams['learning_rate'] = 1e-03\n",
    "\n",
    "# start the training job\n",
    "trainer.fit(litModel, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üíæ Testing and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# automatically loads in the best model weights\n",
    "# according to metric in checkpoint callback\n",
    "results = trainer.test(datamodule=dm, ckpt_path=None) # uses last-saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = f\"{MODEL_SAVE_PATH}.pt\"\n",
    "# save the weights of the model\n",
    "litModel.save_model_weights(path)\n",
    "wandb.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# finish the experiment\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
