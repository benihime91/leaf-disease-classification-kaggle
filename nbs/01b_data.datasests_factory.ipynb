{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.dataset_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for Loading Data from OmegaConf config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import albumentations as A\n",
    "import torchvision.transforms as T\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from src import _logger\n",
    "from src.data.datasets import CassavaDataset, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_transform(cfg: DictConfig, verbose=False):\n",
    "    \"creates transoformations to be used in datasets\"\n",
    "    train_augs_initial = [instantiate(t) for t in cfg.train.before_mix]\n",
    "    train_augs_final   = [instantiate(t) for t in cfg.train.after_mix]\n",
    "    valid_augs = [instantiate(t) for t in cfg.valid]\n",
    "    \n",
    "    if cfg.backend == \"torchvision\":\n",
    "        compose_func = T.Compose\n",
    "    elif cfg.backend == \"albumentations\":\n",
    "        compose_func = A.Compose\n",
    "    \n",
    "    train_augs_initial = compose_func(train_augs_initial)\n",
    "    train_augs_final   = compose_func(train_augs_final)\n",
    "    valid_augs = compose_func(valid_augs)\n",
    "    return train_augs_initial, train_augs_final, valid_augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_loader(cfg: DictConfig):\n",
    "    \"creates a `DataLoader's instance from Cfg`\"\n",
    "    ds_config = cfg.data.dataset\n",
    "    tfm_config = cfg.augmentations\n",
    "    dls_conf = cfg.data.dataloader\n",
    "\n",
    "    transformations = create_transform(tfm_config)\n",
    "\n",
    "    df = load_data(ds_config.csv, ds_config.image_dir,ds_config.fold, shuffle=True)\n",
    "    \n",
    "    trn_df = df.loc[df[\"is_valid\"] == False]\n",
    "    val_df = df.loc[df['is_valid'] == True]\n",
    "\n",
    "    trn_df.reset_index(inplace=True, drop=True)\n",
    "    val_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    _logger.info(\"Data processing configuration for current dataset:\")\n",
    "    _logger.info(f\"\\tinput_size: {cfg.input.input_size}\")\n",
    "    _logger.info(f\"\\tmean: {tuple(cfg.input.mean)}\")\n",
    "    _logger.info(f\"\\tstd: {tuple(cfg.input.std)}\")\n",
    "    _logger.info(f\"\\tinterpolation: {cfg.input.interpolation}\")\n",
    "    _logger.info(\"\")\n",
    "\n",
    "    trn_tfm, tfn_tfm_after, val_tfm = create_transform(tfm_config)\n",
    "\n",
    "    if tfm_config.backend == \"torchvision\":\n",
    "        trn_dset = CassavaDataset.from_torchvision_tfms(trn_df, fn_col=\"filePath\",\n",
    "                                                        label_col=\"label\", transform=trn_tfm)\n",
    "\n",
    "        val_dset = CassavaDataset.from_torchvision_tfms(val_df, fn_col=\"filePath\",\n",
    "                                                        label_col=\"label\", transform=val_tfm)\n",
    "\n",
    "    elif tfm_config.backend == \"albumentations\":\n",
    "        trn_dset = CassavaDataset.from_albu_tfms(trn_df, fn_col=\"filePath\",\n",
    "                                                 label_col=\"label\", transform=trn_tfm)\n",
    "\n",
    "        val_dset = CassavaDataset.from_albu_tfms(val_df, fn_col=\"filePath\",\n",
    "                                                 label_col=\"label\", transform=val_tfm)\n",
    "        \n",
    "    train_dl = DataLoader(trn_dset, shuffle=True, **dls_conf)\n",
    "    val_dl = DataLoader(val_dset, shuffle=True, **dls_conf)\n",
    "    \n",
    "    return train_dl, val_dl, trn_dset, tfn_tfm_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.experimental import initialize, compose\n",
    "from src.models.builder import Net\n",
    "\n",
    "with initialize(\"../conf/\"):\n",
    "    cfg = compose(\"effnet-base\", overrides=['general=default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[32m01/31 06:40:44\u001b[0m \u001b[35m__main__\u001b[0m]: Data processing configuration for current dataset:\n",
      "[\u001b[32m01/31 06:40:44\u001b[0m \u001b[35m__main__\u001b[0m]: \tinput_size: 512\n",
      "[\u001b[32m01/31 06:40:44\u001b[0m \u001b[35m__main__\u001b[0m]: \tmean: (0.42984136, 0.49624753, 0.3129598)\n",
      "[\u001b[32m01/31 06:40:44\u001b[0m \u001b[35m__main__\u001b[0m]: \tstd: (0.21417203, 0.21910103, 0.19542212)\n",
      "[\u001b[32m01/31 06:40:44\u001b[0m \u001b[35m__main__\u001b[0m]: \tinterpolation: random\n",
      "[\u001b[32m01/31 06:40:44\u001b[0m \u001b[35m__main__\u001b[0m]: \n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35m__main__\u001b[0m]: Mixmethod: Snapmix(alpha=5.0, conf_prob=0.5, num_iters=17)\n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: Configuration for the current model :\n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: \t base_network: tf_efficientnet_b3_ns\n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: \t activation: mish\n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: \t drop_path_rate: 0.25\n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: Configuration for model head : \n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: \t class_name: CnnHeadV0\n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: \t n_out: 5\n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: \t pool_type: avg\n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: \t use_conv: False\n",
      "[\u001b[32m01/31 06:40:45\u001b[0m \u001b[35msrc.models.builder\u001b[0m]: \t act_layer: mish\n",
      "[\u001b[32m01/31 06:40:46\u001b[0m \u001b[35msrc.data.mixmethods\u001b[0m]: Snapmix Stopped .\n"
     ]
    }
   ],
   "source": [
    "mixmethod = instantiate(cfg.mixmethod)\n",
    "train_dl, val_dl, train_dset, tfms = create_loader(cfg)\n",
    "\n",
    "_logger.info(f\"Mixmethod: {mixmethod}\")\n",
    "model = Net(cfg)\n",
    "\n",
    "image, target = next(iter(train_dl))\n",
    "image_1 = mixmethod(image, target, model)\n",
    "\n",
    "mixmethod.stop()\n",
    "train_dset.reload_transforms(tfms)\n",
    "train_dl = DataLoader(train_dset, shuffle=True, **cfg.data.dataloader)\n",
    "\n",
    "image, target = next(iter(train_dl))\n",
    "image_2 = mixmethod(image, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.datasets.ipynb.\n",
      "Converted 01a_data.mixmethods.ipynb.\n",
      "Converted 01b_data.datasests_factory.ipynb.\n",
      "Converted 02_losses.ipynb.\n",
      "Converted 03_models.utils.ipynb.\n",
      "Converted 03a_models.builder.ipynb.\n",
      "Converted 03a_models.layers.ipynb.\n",
      "Converted 03b_models.classifiers.ipynb.\n",
      "Converted 04_optimizers.ipynb.\n",
      "Converted 04a_schedulers.ipynb.\n",
      "Converted 05a_lightning.core.ipynb.\n",
      "Converted 05b_lightning.callbacks.ipynb.\n",
      "Converted 05c_lightning.callbacks.progress.ipynb.\n",
      "Converted 06_fastai.core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
