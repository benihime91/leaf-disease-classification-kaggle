lightning:
  callbacks:
    - class_name: pytorch_lightning.callbacks.LearningRateMonitor
      params:
        logging_interval: step

  model_checkpoint:
    filepath: ${training.checkpoint_path}
    monitor: ${training.metric}
    mode: min
    save_top_k: 1

  init_args:
    gpus: 1
    precision: 16
    log_every_n_steps: 10
    max_epochs: ${training.num_epochs}
    benchmark: true
    gradient_clip_val: 0
    max_steps: ${training.total_steps}
    check_val_every_n_epoch: 1
    weights_summary: top
    terminate_on_nan: true
    tpu_cores: null
    progress_bar_refresh_rate: 1
    accumulate_grad_batches: 1
    num_sanity_val_steps: 2
    amp_backend: native
    plugins: null
    limit_train_batches: 1.0
    limit_val_batches: 1.0
    limit_test_batches: 1.0
    min_epochs: 1
