scheduler:
  class_name: torch.optim.lr_scheduler.OneCycleLR
  params:
    max_lr: ${training.lr}
    anneal_strategy: cos
    cycle_momentum: true
    total_steps: ${training.total_steps}
  interval: step
  frequency: 1
  monitor: null
